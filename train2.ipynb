{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57d2f92f",
   "metadata": {},
   "source": [
    "# Computer Vision Analysis\n",
    "#### By Ronny Toribio, Kadir O. Altunel, Michael Cook-Stahl\n",
    "#### Based on [Hands on Machine Learning 2nd edition](https://github.com/ageron/handson-ml2/), [FER2013 candidate1](https://www.kaggle.com/code/ritikjain00/model-training-fer-13), [FER2013 candidate 2](https://www.kaggle.com/code/gauravsharma99/facial-emotion-recognition/notebook) and [Keras Retinanet](https://keras.io/examples/vision/retinanet/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5f3507",
   "metadata": {},
   "source": [
    "### Import modules and declare constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd614254",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_ZOOM = 0.3\n",
    "IMAGE_SHAPE = (48, 48)\n",
    "INPUT_SHAPE = (48, 48, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2debe2",
   "metadata": {},
   "source": [
    "### Utility functions (Bounding Boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9988512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_xy(boxes):\n",
    "    return tf.stack([boxes[:, 1], boxes[:, 0], boxes[:, 3], boxes[:, 2]], axis=-1)\n",
    "\n",
    "\n",
    "def convert_to_xywh(boxes):\n",
    "    return tf.concat(\n",
    "        [(boxes[..., :2] + boxes[..., 2:]) / 2.0, boxes[..., 2:] - boxes[..., :2]],\n",
    "        axis=-1,\n",
    "    )\n",
    "\n",
    "def convert_to_corners(boxes):\n",
    "    return tf.concat(\n",
    "        [boxes[..., :2] - boxes[..., 2:] / 2.0, boxes[..., :2] + boxes[..., 2:] / 2.0],\n",
    "        axis=-1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b9bb04",
   "metadata": {},
   "source": [
    "### Computing pairwise Intersection Over Union (Bounding Boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9282a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2):\n",
    "    boxes1_corners = convert_to_corners(boxes1)\n",
    "    boxes2_corners = convert_to_corners(boxes2)\n",
    "    lu = tf.maximum(boxes1_corners[:, None, :2], boxes2_corners[:, :2])\n",
    "    rd = tf.minimum(boxes1_corners[:, None, 2:], boxes2_corners[:, 2:])\n",
    "    intersection = tf.maximum(0.0, rd - lu)\n",
    "    intersection_area = intersection[:, :, 0] * intersection[:, :, 1]\n",
    "    boxes1_area = boxes1[:, 2] * boxes1[:, 3]\n",
    "    boxes2_area = boxes2[:, 2] * boxes2[:, 3]\n",
    "    union_area = tf.maximum(\n",
    "        boxes1_area[:, None] + boxes2_area - intersection_area, 1e-8\n",
    "    )\n",
    "    return tf.clip_by_value(intersection_area / union_area, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f35b0e",
   "metadata": {},
   "source": [
    "### Anchor Generator (Bounding Boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd541782",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorBox:\n",
    "    def __init__(self):\n",
    "        self.aspect_ratios = [0.5, 1.0, 2.0]\n",
    "        self.scales = [2 ** x for x in [0, 1 / 3, 2 / 3]]\n",
    "        self._num_anchors = len(self.aspect_ratios) * len(self.scales)\n",
    "        self._strides = [2 ** i for i in range(3, 8)]\n",
    "        self._areas = [x ** 2 for x in [32.0, 64.0, 128.0, 256.0, 512.0]]\n",
    "        self._anchor_dims = self._compute_dims()\n",
    "\n",
    "    def _compute_dims(self):\n",
    "        anchor_dims_all = []\n",
    "        for area in self._areas:\n",
    "            anchor_dims = []\n",
    "            for ratio in self.aspect_ratios:\n",
    "                anchor_height = tf.math.sqrt(area / ratio)\n",
    "                anchor_width = area / anchor_height\n",
    "                dims = tf.reshape(\n",
    "                    tf.stack([anchor_width, anchor_height], axis=-1), [1, 1, 2]\n",
    "                )\n",
    "                for scale in self.scales:\n",
    "                    anchor_dims.append(scale * dims)\n",
    "            anchor_dims_all.append(tf.stack(anchor_dims, axis=-2))\n",
    "        return anchor_dims_all\n",
    "\n",
    "    def _get_anchors(self, feature_height, feature_width, level):\n",
    "        rx = tf.range(feature_width, dtype=tf.float32) + 0.5\n",
    "        ry = tf.range(feature_height, dtype=tf.float32) + 0.5\n",
    "        centers = tf.stack(tf.meshgrid(rx, ry), axis=-1) * self._strides[level - 3]\n",
    "        centers = tf.expand_dims(centers, axis=-2)\n",
    "        centers = tf.tile(centers, [1, 1, self._num_anchors, 1])\n",
    "        dims = tf.tile(\n",
    "            self._anchor_dims[level - 3], [feature_height, feature_width, 1, 1]\n",
    "        )\n",
    "        anchors = tf.concat([centers, dims], axis=-1)\n",
    "        return tf.reshape(\n",
    "            anchors, [feature_height * feature_width * self._num_anchors, 4]\n",
    "        )\n",
    "\n",
    "    def get_anchors(self, image_height, image_width):\n",
    "        anchors = [\n",
    "            self._get_anchors(\n",
    "                tf.math.ceil(image_height / 2 ** i),\n",
    "                tf.math.ceil(image_width / 2 ** i),\n",
    "                i,\n",
    "            )\n",
    "            for i in range(3, 8)\n",
    "        ]\n",
    "        return tf.concat(anchors, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71e2fd1",
   "metadata": {},
   "source": [
    "### Classification and box regression heads (Bounding Boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646eba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_head(output_filters, bias_init):\n",
    "    head = keras.Sequential([keras.Input(shape=[None, None, 256])])\n",
    "    kernel_init = tf.initializers.RandomNormal(0.0, 0.01)\n",
    "    for _ in range(4):\n",
    "        head.add(\n",
    "            keras.layers.Conv2D(256, 3, padding=\"same\", kernel_initializer=kernel_init)\n",
    "        )\n",
    "        head.add(keras.layers.ReLU())\n",
    "    head.add(\n",
    "        keras.layers.Conv2D(\n",
    "            output_filters,\n",
    "            3,\n",
    "            1,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=kernel_init,\n",
    "            bias_initializer=bias_init,\n",
    "        )\n",
    "    )\n",
    "    return head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea1fddb",
   "metadata": {},
   "source": [
    "### Feature Pyramid Network as a Keras Layer (Bounding Boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturePyramid(keras.layers.Layer):\n",
    "    def __init__(self, backbone=None, **kwargs):\n",
    "        super(FeaturePyramid, self).__init__(name=\"FeaturePyramid\", **kwargs)\n",
    "        self.backbone = backbone if backbone else get_backbone()\n",
    "        self.conv_c3_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n",
    "        self.conv_c4_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n",
    "        self.conv_c5_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n",
    "        self.conv_c3_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n",
    "        self.conv_c4_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n",
    "        self.conv_c5_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n",
    "        self.conv_c6_3x3 = keras.layers.Conv2D(256, 3, 2, \"same\")\n",
    "        self.conv_c7_3x3 = keras.layers.Conv2D(256, 3, 2, \"same\")\n",
    "        self.upsample_2x = keras.layers.UpSampling2D(2)\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        c3_output, c4_output, c5_output = self.backbone(images, training=training)\n",
    "        p3_output = self.conv_c3_1x1(c3_output)\n",
    "        p4_output = self.conv_c4_1x1(c4_output)\n",
    "        p5_output = self.conv_c5_1x1(c5_output)\n",
    "        p4_output = p4_output + self.upsample_2x(p5_output)\n",
    "        p3_output = p3_output + self.upsample_2x(p4_output)\n",
    "        p3_output = self.conv_c3_3x3(p3_output)\n",
    "        p4_output = self.conv_c4_3x3(p4_output)\n",
    "        p5_output = self.conv_c5_3x3(p5_output)\n",
    "        p6_output = self.conv_c6_3x3(c5_output)\n",
    "        p7_output = self.conv_c7_3x3(tf.nn.relu(p6_output))\n",
    "        return p3_output, p4_output, p5_output, p6_output, p7_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb935b9",
   "metadata": {},
   "source": [
    "### Encoding Labels (Bounding Boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b8620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder:\n",
    "    def __init__(self):\n",
    "        self._anchor_box = AnchorBox()\n",
    "        self._box_variance = tf.convert_to_tensor(\n",
    "            [0.1, 0.1, 0.2, 0.2], dtype=tf.float32\n",
    "        )\n",
    "\n",
    "    def _match_anchor_boxes(\n",
    "        self, anchor_boxes, gt_boxes, match_iou=0.5, ignore_iou=0.4\n",
    "    ):\n",
    "        iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
    "        max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
    "        matched_gt_idx = tf.argmax(iou_matrix, axis=1)\n",
    "        positive_mask = tf.greater_equal(max_iou, match_iou)\n",
    "        negative_mask = tf.less(max_iou, ignore_iou)\n",
    "        ignore_mask = tf.logical_not(tf.logical_or(positive_mask, negative_mask))\n",
    "        return (\n",
    "            matched_gt_idx,\n",
    "            tf.cast(positive_mask, dtype=tf.float32),\n",
    "            tf.cast(ignore_mask, dtype=tf.float32),\n",
    "        )\n",
    "\n",
    "    def _compute_box_target(self, anchor_boxes, matched_gt_boxes):\n",
    "        box_target = tf.concat(\n",
    "            [\n",
    "                (matched_gt_boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:],\n",
    "                tf.math.log(matched_gt_boxes[:, 2:] / anchor_boxes[:, 2:]),\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "        box_target = box_target / self._box_variance\n",
    "        return box_target\n",
    "\n",
    "    def _encode_sample(self, image_shape, gt_boxes, cls_ids):\n",
    "        anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
    "        cls_ids = tf.cast(cls_ids, dtype=tf.float32)\n",
    "        matched_gt_idx, positive_mask, ignore_mask = self._match_anchor_boxes(\n",
    "            anchor_boxes, gt_boxes\n",
    "        )\n",
    "        matched_gt_boxes = tf.gather(gt_boxes, matched_gt_idx)\n",
    "        box_target = self._compute_box_target(anchor_boxes, matched_gt_boxes)\n",
    "        matched_gt_cls_ids = tf.gather(cls_ids, matched_gt_idx)\n",
    "        cls_target = tf.where(\n",
    "            tf.not_equal(positive_mask, 1.0), -1.0, matched_gt_cls_ids\n",
    "        )\n",
    "        cls_target = tf.where(tf.equal(ignore_mask, 1.0), -2.0, cls_target)\n",
    "        cls_target = tf.expand_dims(cls_target, axis=-1)\n",
    "        label = tf.concat([box_target, cls_target], axis=-1)\n",
    "        return label\n",
    "\n",
    "    def encode_batch(self, batch_images, gt_boxes, cls_ids):\n",
    "        images_shape = tf.shape(batch_images)\n",
    "        batch_size = images_shape[0]\n",
    "\n",
    "        labels = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
    "        for i in range(batch_size):\n",
    "            label = self._encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
    "            labels = labels.write(i, label)\n",
    "        batch_images = tf.keras.applications.resnet.preprocess_input(batch_images)\n",
    "        return batch_images, labels.stack()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91749261",
   "metadata": {},
   "source": [
    "### Retinanet (Bounding Boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5968a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinaNet(keras.Model):\n",
    "    def __init__(self, num_classes, backbone=None, **kwargs):\n",
    "        super(RetinaNet, self).__init__(name=\"RetinaNet\", **kwargs)\n",
    "        self.fpn = FeaturePyramid(backbone)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))\n",
    "        self.cls_head = build_head(9 * num_classes, prior_probability)\n",
    "        self.box_head = build_head(9 * 4, \"zeros\")\n",
    "\n",
    "    def call(self, image, training=False):\n",
    "        features = self.fpn(image, training=training)\n",
    "        N = tf.shape(image)[0]\n",
    "        cls_outputs = []\n",
    "        box_outputs = []\n",
    "        for feature in features:\n",
    "            box_outputs.append(tf.reshape(self.box_head(feature), [N, -1, 4]))\n",
    "            cls_outputs.append(\n",
    "                tf.reshape(self.cls_head(feature), [N, -1, self.num_classes])\n",
    "            )\n",
    "        cls_outputs = tf.concat(cls_outputs, axis=1)\n",
    "        box_outputs = tf.concat(box_outputs, axis=1)\n",
    "        return tf.concat([box_outputs, cls_outputs], axis=-1)\n",
    "\n",
    "class RetinaNetBoxLoss(tf.losses.Loss):\n",
    "    def __init__(self, delta):\n",
    "        super(RetinaNetBoxLoss, self).__init__(\n",
    "            reduction=\"none\", name=\"RetinaNetBoxLoss\"\n",
    "        )\n",
    "        self._delta = delta\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        difference = y_true - y_pred\n",
    "        absolute_difference = tf.abs(difference)\n",
    "        squared_difference = difference ** 2\n",
    "        loss = tf.where(\n",
    "            tf.less(absolute_difference, self._delta),\n",
    "            0.5 * squared_difference,\n",
    "            absolute_difference - 0.5,\n",
    "        )\n",
    "        return tf.reduce_sum(loss, axis=-1)\n",
    "\n",
    "class RetinaNetClassificationLoss(tf.losses.Loss):\n",
    "    def __init__(self, alpha, gamma):\n",
    "        super(RetinaNetClassificationLoss, self).__init__(\n",
    "            reduction=\"none\", name=\"RetinaNetClassificationLoss\"\n",
    "        )\n",
    "        self._alpha = alpha\n",
    "        self._gamma = gamma\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=y_true, logits=y_pred\n",
    "        )\n",
    "        probs = tf.nn.sigmoid(y_pred)\n",
    "        alpha = tf.where(tf.equal(y_true, 1.0), self._alpha, (1.0 - self._alpha))\n",
    "        pt = tf.where(tf.equal(y_true, 1.0), probs, 1 - probs)\n",
    "        loss = alpha * tf.pow(1.0 - pt, self._gamma) * cross_entropy\n",
    "        return tf.reduce_sum(loss, axis=-1)\n",
    "\n",
    "class RetinaNetLoss(tf.losses.Loss):\n",
    "    def __init__(self, num_classes=80, alpha=0.25, gamma=2.0, delta=1.0):\n",
    "        super(RetinaNetLoss, self).__init__(reduction=\"auto\", name=\"RetinaNetLoss\")\n",
    "        self._clf_loss = RetinaNetClassificationLoss(alpha, gamma)\n",
    "        self._box_loss = RetinaNetBoxLoss(delta)\n",
    "        self._num_classes = num_classes\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "        box_labels = y_true[:, :, :4]\n",
    "        box_predictions = y_pred[:, :, :4]\n",
    "        cls_labels = tf.one_hot(\n",
    "            tf.cast(y_true[:, :, 4], dtype=tf.int32),\n",
    "            depth=self._num_classes,\n",
    "            dtype=tf.float32,\n",
    "        )\n",
    "        cls_predictions = y_pred[:, :, 4:]\n",
    "        positive_mask = tf.cast(tf.greater(y_true[:, :, 4], -1.0), dtype=tf.float32)\n",
    "        ignore_mask = tf.cast(tf.equal(y_true[:, :, 4], -2.0), dtype=tf.float32)\n",
    "        clf_loss = self._clf_loss(cls_labels, cls_predictions)\n",
    "        box_loss = self._box_loss(box_labels, box_predictions)\n",
    "        clf_loss = tf.where(tf.equal(ignore_mask, 1.0), 0.0, clf_loss)\n",
    "        box_loss = tf.where(tf.equal(positive_mask, 1.0), box_loss, 0.0)\n",
    "        normalizer = tf.reduce_sum(positive_mask, axis=-1)\n",
    "        clf_loss = tf.math.divide_no_nan(tf.reduce_sum(clf_loss, axis=-1), normalizer)\n",
    "        box_loss = tf.math.divide_no_nan(tf.reduce_sum(box_loss, axis=-1), normalizer)\n",
    "        loss = clf_loss + box_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3ede6a",
   "metadata": {},
   "source": [
    "### Load Facial Emotion Recognition dataset\n",
    "#### training, validation, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03cb153",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=IMAGE_ZOOM, horizontal_flip=True,\n",
    "                                   validation_split=0.10)\n",
    "Xy_train = train_datagen.flow_from_directory(os.path.join(\"fer2013\", \"train\"), batch_size=BATCH_SIZE, \n",
    "                                   target_size=IMAGE_SHAPE, shuffle=True, subset=\"training\",\n",
    "                                   color_mode=\"grayscale\", class_mode=\"categorical\")\n",
    "\n",
    "Xy_valid = train_datagen.flow_from_directory(os.path.join(\"fer2013\", \"train\"), batch_size=BATCH_SIZE, \n",
    "                                   target_size=IMAGE_SHAPE, shuffle=True, subset=\"validation\",\n",
    "                                   color_mode=\"grayscale\", class_mode=\"categorical\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\n",
    "Xy_test = test_datagen.flow_from_directory(os.path.join(\"fer2013\", \"test\"), batch_size=BATCH_SIZE,\n",
    "                                   target_size=IMAGE_SHAPE, shuffle=True,\n",
    "                                   color_mode=\"grayscale\", class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb37c6f",
   "metadata": {},
   "source": [
    "### Build CNN model (Without Classification Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca4cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # Convolution Block 1\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\", input_shape=INPUT_SHAPE),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Convolution Block 2\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), padding=\"valid\", activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2), padding=\"valid\"),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Classification Block\n",
    "    #Flatten(),\n",
    "    #Dense(1024, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    #BatchNormalization(),\n",
    "    #Dropout(0.5),\n",
    "    #Dense(7, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d280748",
   "metadata": {},
   "source": [
    "### Attach retinanet to our model for bounding box regression and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9c8fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = RetinaNetLoss(7) # 7 emotion classes\n",
    "model = RetinaNet(7, model) # attach retinanet to our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0071e55e",
   "metadata": {},
   "source": [
    "### Model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9568b601",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee7e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c244bac8",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9329e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [2.5e-06, 0.000625, 0.00125, 0.0025, 0.00025, 2.5e-05]\n",
    "learning_rate_boundaries = [125, 250, 500, 240000, 360000]\n",
    "learning_rate_fn = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=learning_rate_boundaries, values=learning_rates\n",
    ")\n",
    "\n",
    "model.compile(loss=loss_fn, optimizer=Nadam(learning_rate=learning_rate_fn, beta_1=0.9, epsilon=1e-07),\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bca87a",
   "metadata": {},
   "source": [
    "### Save Architecture as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c8bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"cnn_model2.json\") as f:\n",
    "    f.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e30d9",
   "metadata": {},
   "source": [
    "### Checkpoint callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec3df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = ModelCheckpoint(\"cnn_model2_weights.h5\", monitor=\"val_accuracy\",\n",
    "                                verbose=1, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aac76b7",
   "metadata": {},
   "source": [
    "### Early stopping callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd447c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = EarlyStopping(monitor=\"val_accuracy\", min_delta=0.00005,\n",
    "                                  patience=11, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a927508",
   "metadata": {},
   "source": [
    "### Reduce learning rate on plateau callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751dad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr_cb = ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.5, patience=7, min_l=1e-7, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03676b3",
   "metadata": {},
   "source": [
    "### CSV callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb609ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_cb = CSVLogger(\"cnn_model2_training.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b2dfad",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b75ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(Xy_train, epochs=60, validation_data=(Xy_valid),\n",
    "                    steps_per_epoch=Xy_train.n // BATCH_SIZE,\n",
    "                    validation_steps=Xy_valid.n // BATCH_SIZE,\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb, reduce_lr_cb, csv_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bac2f6",
   "metadata": {},
   "source": [
    "### Roll back to the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ddf8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"cnn_model2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e9317",
   "metadata": {},
   "source": [
    "### Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e682a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_epoch = [x - 0.5 for x in history.epoch]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "ax.grid(True)\n",
    "ax.plot(history.epoch, history.history[\"loss\"], \"b-\", label=\"loss\")\n",
    "ax.plot(history.epoch, history.history[\"accuracy\"], \"r-\", label=\"accuracy\")\n",
    "ax.plot(adjusted_epoch, history.history[\"val_loss\"], \"c-\", label=\"val_loss\")\n",
    "ax.plot(adjusted_epoch, history.history[\"val_accuracy\"], \"g-\", label=\"val_accuracy\")\n",
    "ax.legend()\n",
    "fig.savefig(\"cnn_model2_training.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2206ba34",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeaf6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate train set\")\n",
    "model.evaluate(Xy_train)\n",
    "print(\"Evaluate validation set\")\n",
    "model.evaluate(Xy_valid)\n",
    "print(\"Evaluate test set\")\n",
    "model.evaluate(Xy_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
