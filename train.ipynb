{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57d2f92f",
   "metadata": {},
   "source": [
    "# Computer Vision Analysis\n",
    "#### By Ronny Toribio, Kadir O. Altunel, Michael Cook-Stahl\n",
    "#### Based on [Hands on Machine Learning 2nd edition](https://github.com/ageron/handson-ml2/), [FER2013 candidate 1](https://www.kaggle.com/code/ritikjain00/model-training-fer-13) and [FER2013 candidate 2](https://www.kaggle.com/code/gauravsharma99/facial-emotion-recognition/notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5f3507",
   "metadata": {},
   "source": [
    "### Import modules and declare constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd614254",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_ZOOM = 0.3\n",
    "IMAGE_SHAPE = (48, 48)\n",
    "INPUT_SHAPE = (48, 48, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3ede6a",
   "metadata": {},
   "source": [
    "### Load Facial Emotion Recognition dataset\n",
    "#### training, validation, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03cb153",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=IMAGE_ZOOM, horizontal_flip=True,\n",
    "                                   validation_split=0.10)\n",
    "Xy_train = train_datagen.flow_from_directory(os.path.join(\"fer2013\", \"train\"), batch_size=BATCH_SIZE, \n",
    "                                   target_size=IMAGE_SHAPE, shuffle=True, subset=\"training\",\n",
    "                                   color_mode=\"grayscale\", class_mode=\"categorical\")\n",
    "\n",
    "Xy_valid = train_datagen.flow_from_directory(os.path.join(\"fer2013\", \"train\"), batch_size=BATCH_SIZE, \n",
    "                                   target_size=IMAGE_SHAPE, shuffle=True, subset=\"validation\",\n",
    "                                   color_mode=\"grayscale\", class_mode=\"categorical\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\n",
    "Xy_test = test_datagen.flow_from_directory(os.path.join(\"fer2013\", \"test\"), batch_size=BATCH_SIZE,\n",
    "                                   target_size=IMAGE_SHAPE, shuffle=True,\n",
    "                                   color_mode=\"grayscale\", class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb37c6f",
   "metadata": {},
   "source": [
    "### Build CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca4cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # Convolution Block 1\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\", input_shape=INPUT_SHAPE),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Convolution Block 2\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), padding=\"valid\", activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2), padding=\"valid\"),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Classification Block\n",
    "    Flatten(),\n",
    "    Dense(1024, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(7, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0071e55e",
   "metadata": {},
   "source": [
    "### Model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9568b601",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee7e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c244bac8",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9329e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=Nadam(learning_rate=0.001, beta_1=0.9, epsilon=1e-07),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334db644",
   "metadata": {},
   "source": [
    "### Save Architecture as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef59fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"cnn_model.json\") as f:\n",
    "    f.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e30d9",
   "metadata": {},
   "source": [
    "### Checkpoint callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec3df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = ModelCheckpoint(\"cnn_model_weights.h5\", monitor=\"val_accuracy\",\n",
    "                                verbose=1, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aac76b7",
   "metadata": {},
   "source": [
    "### Early stopping callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd447c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = EarlyStopping(monitor=\"val_accuracy\", min_delta=0.00005,\n",
    "                                  patience=11, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a927508",
   "metadata": {},
   "source": [
    "### Reduce learning rate on plateau callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751dad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr_cb = ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.5, patience=7, min_l=1e-7, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96816b4",
   "metadata": {},
   "source": [
    "### CSV callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe72b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_cb = CSVLogger(\"cnn_model_training.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b2dfad",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b75ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(Xy_train, epochs=60, validation_data=(Xy_valid),\n",
    "                    steps_per_epoch=Xy_train.n // BATCH_SIZE,\n",
    "                    validation_steps=Xy_valid.n // BATCH_SIZE,\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb, reduce_lr_cb, csv_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bac2f6",
   "metadata": {},
   "source": [
    "### Roll back to the best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ddf8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"cnn_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e9317",
   "metadata": {},
   "source": [
    "### Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e682a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjusted_epoch = [x - 0.5 for x in history.epoch]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "ax.grid(True)\n",
    "ax.plot(history.epoch, history.history[\"loss\"], \"b-\", label=\"loss\")\n",
    "ax.plot(history.epoch, history.history[\"accuracy\"], \"r-\", label=\"accuracy\")\n",
    "ax.plot(history.epoch, history.history[\"val_loss\"], \"c-\", label=\"val_loss\")\n",
    "ax.plot(history.epoch, history.history[\"val_accuracy\"], \"g-\", label=\"val_accuracy\")\n",
    "ax.legend()\n",
    "fig.savefig(\"cnn_model_training.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2206ba34",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeaf6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate train set\")\n",
    "model.evaluate(Xy_train)\n",
    "print(\"Evaluate validation set\")\n",
    "model.evaluate(Xy_valid)\n",
    "print(\"Evaluate test set\")\n",
    "model.evaluate(Xy_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
