{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Z5VuAlC3R0yh",
   "metadata": {
    "id": "Z5VuAlC3R0yh"
   },
   "source": [
    "# Computer Vision Analysis\n",
    "#### By Ronny Toribio, Kadir O. Altunel, Michael Cook-Stahl\n",
    "#### Based on [Hands on Machine Learning 2nd edition](https://github.com/ageron/handson-ml2/), [FER2013 candidate 1](https://www.kaggle.com/code/ritikjain00/model-training-fer-13) and [FER2013 candidate 2](https://www.kaggle.com/code/gauravsharma99/facial-emotion-recognition/notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t9BVYDwBR0ym",
   "metadata": {
    "id": "t9BVYDwBR0ym"
   },
   "source": [
    "### Import modules and declare constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FrDuFczgR0yn",
   "metadata": {
    "id": "FrDuFczgR0yn"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization,\n",
    "     LeakyReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, CSVLogger, ModelCheckpoint \n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0VXelRyIR0yp",
   "metadata": {
    "id": "0VXelRyIR0yp"
   },
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YX16VTJoR0yq",
   "metadata": {
    "id": "YX16VTJoR0yq"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_ZOOM = 0.3\n",
    "IMAGE_SHAPE = (48, 48)\n",
    "INPUT_SHAPE = (48, 48, 1)\n",
    "TRAIN_DIR = os.path.join(\"fer2013\", \"train\")\n",
    "TEST_DIR = os.path.join(\"fer2013\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z58JCINW9oFx",
   "metadata": {
    "id": "z58JCINW9oFx"
   },
   "source": [
    "### Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xDczGY4M9zjB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDczGY4M9zjB",
    "outputId": "02af2cc6-cffe-4e86-bd57-7c2c77646c1f"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "!unzip /content/drive/MyDrive/FER.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TjEEOXKRR0yq",
   "metadata": {
    "id": "TjEEOXKRR0yq"
   },
   "source": [
    "### Load Facial Emotion Recognition dataset\n",
    "#### training, validation, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hWfl8NDJR0yr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWfl8NDJR0yr",
    "outputId": "8589586c-c8e2-4408-98b4-8dac21cf0bd1"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=IMAGE_ZOOM, horizontal_flip=True,\n",
    "                                   validation_split=0.10)\n",
    "Xy_train = train_datagen.flow_from_directory(TRAIN_DIR, batch_size=BATCH_SIZE, \n",
    "                                   target_size=IMAGE_SHAPE, shuffle=True, subset=\"training\",\n",
    "                                   color_mode=\"grayscale\", class_mode=\"categorical\")\n",
    "\n",
    "Xy_valid = train_datagen.flow_from_directory(TRAIN_DIR, batch_size=BATCH_SIZE, \n",
    "                                   target_size=IMAGE_SHAPE, shuffle=True, subset=\"validation\",\n",
    "                                   color_mode=\"grayscale\", class_mode=\"categorical\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "Xy_test = test_datagen.flow_from_directory(TEST_DIR, batch_size=BATCH_SIZE * 1000,\n",
    "                                   target_size=IMAGE_SHAPE, shuffle=True,\n",
    "                                   color_mode=\"grayscale\", class_mode=\"categorical\")\n",
    "\n",
    "y_test = Xy_test[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pgUbpnyxR0ys",
   "metadata": {
    "id": "pgUbpnyxR0ys"
   },
   "source": [
    "### Build and compile CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BIqKQeCLR0ys",
   "metadata": {
    "id": "BIqKQeCLR0ys"
   },
   "outputs": [],
   "source": [
    "def build_model(main_activation, main_initializer, use_conv_block3=False):\n",
    "    model = Sequential(name=\"cnn_model\")\n",
    "    # Convolution Block 0\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "              kernel_initializer= main_initializer, input_shape=INPUT_SHAPE,\n",
    "              name=\"conv_block_0_conv_layer_0_input\"))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "              kernel_initializer= main_initializer, name=\"conv_block_0_conv_layer_1\"))\n",
    "    model.add(BatchNormalization(name=\"conv_block_0_batchnorm\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\", name=\"conv_block_0_maxpool\"))\n",
    "    model.add(Dropout(0.25, name=\"conv_block_0_dropout\"))\n",
    "\n",
    "    # Convolution Block 1\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "              kernel_initializer= main_initializer, kernel_regularizer=l2(0.01), name=\"conv_block_1_conv_layer_0\"))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "              kernel_initializer= main_initializer, kernel_regularizer=l2(0.01), name=\"conv_block_1_conv_layer_1\"))\n",
    "    model.add(BatchNormalization(name=\"conv_block_1_batchnorm\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"valid\", name=\"conv_block_1_maxpool\"))\n",
    "    model.add(Dropout(0.25, name=\"conv_block_1_dropout\"))\n",
    "        \n",
    "    # Convolution Block 2\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "              kernel_initializer= main_initializer, kernel_regularizer=l2(0.01),\n",
    "              name=\"conv_block_2_conv_layer_0\"))\n",
    "    model.add(Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "              kernel_initializer= main_initializer, kernel_regularizer=l2(0.01), \n",
    "              name=\"conv_block_2_conv_layer_1\"))\n",
    "    model.add(BatchNormalization(name=\"conv_block_2_batchnorm\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"valid\", name=\"conv_block_2_maxpool\"))\n",
    "    model.add(Dropout(0.25, name=\"conv_block_2_dropout\"))\n",
    "    \n",
    "    # Convolution Block 3\n",
    "    if use_conv_block3:\n",
    "        model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "                  kernel_initializer= main_initializer, kernel_regularizer=l2(0.01),\n",
    "                  name=\"conv_block_3_conv_layer_0\"))\n",
    "        model.add(Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "                  kernel_initializer= main_initializer, kernel_regularizer=l2(0.01), \n",
    "                  name=\"conv_block_3_conv_layer_1\"))\n",
    "        model.add(BatchNormalization(name=\"conv_block_3_batchnorm\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"valid\", name=\"conv_block_3_maxpool\"))\n",
    "        model.add(Dropout(0.25, name=\"conv_block_3_dropout\"))\n",
    "\n",
    "    # Classification Block\n",
    "    model.add(Flatten(name=\"class_block_flatten\"))\n",
    "    model.add(Dense(1024, activation=main_activation, kernel_initializer=\"he_normal\",\n",
    "              name=\"class_block_flatten_dense_0\"))\n",
    "    model.add(BatchNormalization(name=\"class_block_batchnorm\"))\n",
    "    model.add(Dropout(0.5, name=\"class_block_dropout\"))\n",
    "    model.add(Dense(7, activation=\"softmax\", name=\"class_block_dense_output\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.0001, decay=1e-6),\n",
    "              metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def build_model_with_activation_layers(main_activation_layer, main_activation_name, use_conv_block3=False):\n",
    "    model = Sequential(name=\"cnn_model\")\n",
    "    # Convolution Block 0\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", input_shape=INPUT_SHAPE,\n",
    "              name=\"conv_block_0_conv_layer_0_input\"))\n",
    "    model.add(main_activation_layer, name=\"conv_block_0_{}_0\".format(main_activation_name))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", name=\"conv_block_0_conv_layer_1\"))\n",
    "    model.add(main_activation_layer, name=\"conv_block_0_{}_1\".format(main_activation_name))\n",
    "    model.add(BatchNormalization(name=\"conv_block_0_batchnorm\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\", name=\"conv_block_0_maxpool\"))\n",
    "    model.add(Dropout(0.25, name=\"conv_block_0_dropout\"))\n",
    "\n",
    "    # Convolution Block 1\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", kernel_regularizer=l2(0.01),\n",
    "              name=\"conv_block_1_conv_layer_0\"))\n",
    "    model.add(main_activation_layer, name=\"conv_block_1_{}_0\".format(main_activation_name))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", kernel_regularizer=l2(0.01),\n",
    "              name=\"conv_block_1_conv_layer_1\"))\n",
    "    model.add(main_activation_layer, name=\"conv_block_1_{}_1\".format(main_activation_name))\n",
    "    model.add(BatchNormalization(name=\"conv_block_1_batchnorm\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"valid\", name=\"conv_block_1_maxpool\"))\n",
    "    model.add(Dropout(0.25, name=\"conv_block_1_dropout\"))\n",
    "        \n",
    "    # Convolution Block 2\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", kernel_regularizer=l2(0.01),\n",
    "              name=\"conv_block_2_conv_layer_0\"))\n",
    "    model.add(main_activation_layer, name=\"conv_block_2_{}_0\".format(main_activation_name))\n",
    "    model.add(Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\", kernel_regularizer=l2(0.01), \n",
    "              name=\"conv_block_2_conv_layer_1\"))\n",
    "    model.add(main_activation_layer, name=\"conv_block_2_{}_1\".format(main_activation_name))\n",
    "    model.add(BatchNormalization(name=\"conv_block_2_batchnorm\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"valid\", name=\"conv_block_2_maxpool\"))\n",
    "    model.add(Dropout(0.25, name=\"conv_block_2_dropout\"))\n",
    "    \n",
    "    # Convolution Block 3\n",
    "    if use_conv_block3:\n",
    "        model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", kernel_regularizer=l2(0.01),\n",
    "                  name=\"conv_block_3_conv_layer_0\"))\n",
    "        model.add(main_activation_layer, name=\"conv_block_3_{}_0\".format(main_activation_name))\n",
    "        model.add(Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\", kernel_regularizer=l2(0.01), \n",
    "                  name=\"conv_block_3_conv_layer_1\"))\n",
    "        model.add(main_activation_layer, name=\"conv_block_3_{}_1\".format(main_activation_name))\n",
    "        model.add(BatchNormalization(name=\"conv_block_3_batchnorm\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"valid\", name=\"conv_block_3_maxpool\"))\n",
    "        model.add(Dropout(0.25, name=\"conv_block_3_dropout\"))\n",
    "\n",
    "    # Classification Block\n",
    "    model.add(Flatten(name=\"class_block_flatten\"))\n",
    "    model.add(Dense(1024, name=\"class_block_flatten_dense_0\"))\n",
    "    model.add(main_activation_layer, name=\"class_block_{}_0\".format(main_activation_name))\n",
    "    model.add(BatchNormalization(name=\"class_block_batchnorm\"))\n",
    "    model.add(Dropout(0.5, name=\"class_block_dropout\"))\n",
    "    model.add(Dense(7, activation=\"softmax\", name=\"class_block_dense_output\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.0001, decay=1e-6),\n",
    "              metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kn0Z_MmHR0yt",
   "metadata": {
    "id": "kn0Z_MmHR0yt"
   },
   "source": [
    "### Early stopping callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p6bwkyo5R0yu",
   "metadata": {
    "id": "p6bwkyo5R0yu"
   },
   "outputs": [],
   "source": [
    "early_stopping_cb = EarlyStopping(min_delta=0.00005, patience=11, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tBLRTBV_R0yu",
   "metadata": {
    "id": "tBLRTBV_R0yu"
   },
   "source": [
    "### Reduce learning rate on plateau callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JHdcC0DaR0yv",
   "metadata": {
    "id": "JHdcC0DaR0yv"
   },
   "outputs": [],
   "source": [
    "reduce_lr_cb = ReduceLROnPlateau(factor=0.5, patience=7, min_l=1e-7, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QC6W089cR0yv",
   "metadata": {
    "id": "QC6W089cR0yv"
   },
   "source": [
    "### Grid Search Hyperparameters for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4wdiDF4qR0yv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wdiDF4qR0yv",
    "outputId": "e2c2238a-053f-4540-882d-f2b00d5c74eb"
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\"main_activation\": [\"relu\"], \"main_initializer\":[\"he_normal\"], \"use_conv_block3\": [True, False]},\n",
    "    {\"main_activation_layer\": [LeakyReLU(kernel_initializer=\"he_normal\")], \"main_activation_name\": [\"leaky_relu\"],\n",
    "     \"use_conv_block3\": [True, False]}\n",
    "]\n",
    "model_scores = {}\n",
    "best_model = None\n",
    "best_model_score = None\n",
    "best_model_history = None\n",
    "best_model_name = \"\"\n",
    "\n",
    "for params in list(ParameterGrid(param_grid)):\n",
    "    cur_name = \"\"\n",
    "    cur_model = None\n",
    "    if \"main_activation\" in params:\n",
    "        cur_name = \"{}+{}+{}\".format(params[\"main_activation_name\"], params[\"main_initializer\"],\n",
    "                                     params[\"use_conv_block3\"])\n",
    "        cur_model = build_model(**params)\n",
    "    else:\n",
    "        cur_name = \"{}+{}\".format(params[\"main_activation_name\"], params[\"use_conv_block3\"])\n",
    "        cur_model = build_model_with_activation_layers(**params)\n",
    "    print(cur_name)\n",
    "    if cur_model is None:\n",
    "        continue\n",
    "    model_json = cur_model.to_json()\n",
    "    with open(cur_name + \".json\", \"w\") as f:\n",
    "        f.write(model_json)\n",
    "    csv_cb = CSVLogger(cur_name + \"-training.txt\")\n",
    "    cur_weights = cur_name + \"-weights.h5\"\n",
    "    checkpoint_cb = ModelCheckpoint(cur_weights, monitor = 'accuracy', verbose =1, \n",
    "                                    save_best_only = True, save_weights_only = True)\n",
    "    history = cur_model.fit(Xy_train, epochs=80,\n",
    "                            validation_data=(Xy_valid),\n",
    "                            steps_per_epoch=Xy_train.n // BATCH_SIZE,\n",
    "                            validation_steps=Xy_valid.n // BATCH_SIZE,\n",
    "                            callbacks=[early_stopping_cb, reduce_lr_cb, \n",
    "                                       csv_cb, checkpoint_cb])\n",
    "    cur_model.load_weights(cur_weights)\n",
    "    loss, accuracy = cur_model.evaluate(Xy_test)\n",
    "    print(\"Best: {} Score: {} Loss: {}\".format(cur_name, accuracy, loss))\n",
    "    model_scores[cur_name] = accuracy\n",
    "    if best_model_score is None or accuracy > best_model_score:\n",
    "        best_model_score = accuracy\n",
    "        best_model = cur_model\n",
    "        best_model_history = history\n",
    "        best_model_name = cur_name\n",
    "\n",
    "print()\n",
    "print(\"Best: {} Score: {}\".format(best_model_name, best_model_score))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "machine_shape": "hm",
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
