{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Z5VuAlC3R0yh",
   "metadata": {
    "id": "Z5VuAlC3R0yh"
   },
   "source": [
    "# Computer Vision Analysis\n",
    "### Keras Grid Search of CNN models\n",
    "#### By Ronny Toribio, Kadir O. Altunel, Michael Cook-Stahl\n",
    "#### Based on [Hands on Machine Learning 2nd edition](https://github.com/ageron/handson-ml2/), [FER2013 candidate 1](https://www.kaggle.com/code/ritikjain00/model-training-fer-13) and [FER2013 candidate 2](https://www.kaggle.com/code/gauravsharma99/facial-emotion-recognition/notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t9BVYDwBR0ym",
   "metadata": {
    "id": "t9BVYDwBR0ym"
   },
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FrDuFczgR0yn",
   "metadata": {
    "id": "FrDuFczgR0yn"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, CSVLogger, ModelCheckpoint \n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0VXelRyIR0yp",
   "metadata": {
    "id": "0VXelRyIR0yp"
   },
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YX16VTJoR0yq",
   "metadata": {
    "id": "YX16VTJoR0yq"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_ZOOM = 0.3\n",
    "IMAGE_SHAPE = (48, 48)\n",
    "INPUT_SHAPE = (48, 48, 1)\n",
    "TRAIN_DIR = os.path.join(\"fer2013\", \"train\")\n",
    "TEST_DIR = os.path.join(\"fer2013\", \"test\")\n",
    "GOOGLE_DRIVE_PATH = \"/content/drive/MyDrive/Machine Learning/GridSearch\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z58JCINW9oFx",
   "metadata": {
    "id": "z58JCINW9oFx"
   },
   "source": [
    "### Mount Google Drive and unzip dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xDczGY4M9zjB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDczGY4M9zjB",
    "outputId": "6c7900bc-dce4-44be-e1aa-6d241216d24b"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "os.makedirs(GOOGLE_DRIVE_PATH, exist_ok=True)\n",
    "!unzip /content/drive/MyDrive/FER.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TjEEOXKRR0yq",
   "metadata": {
    "id": "TjEEOXKRR0yq"
   },
   "source": [
    "### Load Facial Emotion Recognition dataset\n",
    "#### training, validation, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hWfl8NDJR0yr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWfl8NDJR0yr",
    "outputId": "854137aa-574b-4de6-dfee-8c74384ac8bc"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=IMAGE_ZOOM, horizontal_flip=True,\n",
    "                                   validation_split=0.10)\n",
    "Xy_train = train_datagen.flow_from_directory(TRAIN_DIR, batch_size=BATCH_SIZE, \n",
    "                                   target_size=IMAGE_SHAPE, shuffle=True, subset=\"training\",\n",
    "                                   color_mode=\"grayscale\", class_mode=\"categorical\")\n",
    "\n",
    "Xy_valid = train_datagen.flow_from_directory(TRAIN_DIR, batch_size=BATCH_SIZE, \n",
    "                                   target_size=IMAGE_SHAPE, shuffle=True, subset=\"validation\",\n",
    "                                   color_mode=\"grayscale\", class_mode=\"categorical\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "Xy_test = test_datagen.flow_from_directory(TEST_DIR, batch_size=BATCH_SIZE,\n",
    "                                   target_size=IMAGE_SHAPE, shuffle=True,\n",
    "                                   color_mode=\"grayscale\", class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pgUbpnyxR0ys",
   "metadata": {
    "id": "pgUbpnyxR0ys"
   },
   "source": [
    "### Build and compile CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BIqKQeCLR0ys",
   "metadata": {
    "id": "BIqKQeCLR0ys"
   },
   "outputs": [],
   "source": [
    "def build_model(main_activation, main_initializer, use_conv_block3=False):\n",
    "    model = Sequential(name=\"cnn_model\")\n",
    "    # Convolution Block 0\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "              kernel_initializer= main_initializer, input_shape=INPUT_SHAPE,\n",
    "              name=\"conv_block_0_conv_layer_0_input\"))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "              kernel_initializer= main_initializer, name=\"conv_block_0_conv_layer_1\"))\n",
    "    model.add(BatchNormalization(name=\"conv_block_0_batchnorm\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\", name=\"conv_block_0_maxpool\"))\n",
    "    model.add(Dropout(0.25, name=\"conv_block_0_dropout\"))\n",
    "\n",
    "    # Convolution Block 1\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "              kernel_initializer= main_initializer, kernel_regularizer=l2(0.01), name=\"conv_block_1_conv_layer_0\"))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "              kernel_initializer= main_initializer, kernel_regularizer=l2(0.01), name=\"conv_block_1_conv_layer_1\"))\n",
    "    model.add(BatchNormalization(name=\"conv_block_1_batchnorm\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"valid\", name=\"conv_block_1_maxpool\"))\n",
    "    model.add(Dropout(0.25, name=\"conv_block_1_dropout\"))\n",
    "        \n",
    "    # Convolution Block 2\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "              kernel_initializer= main_initializer, kernel_regularizer=l2(0.01),\n",
    "              name=\"conv_block_2_conv_layer_0\"))\n",
    "    model.add(Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "              kernel_initializer= main_initializer, kernel_regularizer=l2(0.01), \n",
    "              name=\"conv_block_2_conv_layer_1\"))\n",
    "    model.add(BatchNormalization(name=\"conv_block_2_batchnorm\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"valid\", name=\"conv_block_2_maxpool\"))\n",
    "    model.add(Dropout(0.25, name=\"conv_block_2_dropout\"))\n",
    "    \n",
    "    # Convolution Block 3\n",
    "    if use_conv_block3:\n",
    "        model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "                  kernel_initializer= main_initializer, kernel_regularizer=l2(0.01),\n",
    "                  name=\"conv_block_3_conv_layer_0\"))\n",
    "        model.add(Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "                  kernel_initializer= main_initializer, kernel_regularizer=l2(0.01), \n",
    "                  name=\"conv_block_3_conv_layer_1\"))\n",
    "        model.add(BatchNormalization(name=\"conv_block_3_batchnorm\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"valid\", name=\"conv_block_3_maxpool\"))\n",
    "        model.add(Dropout(0.25, name=\"conv_block_3_dropout\"))\n",
    "\n",
    "    # Classification Block\n",
    "    model.add(Flatten(name=\"class_block_flatten\"))\n",
    "    model.add(Dense(2048, activation=main_activation, kernel_initializer=\"he_normal\",\n",
    "              name=\"class_block_flatten_dense_0\"))\n",
    "    model.add(BatchNormalization(name=\"class_block_batchnorm\"))\n",
    "    model.add(Dropout(0.5, name=\"class_block_dropout\"))\n",
    "    model.add(Dense(7, activation=\"softmax\", name=\"class_block_dense_output\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.0001, decay=1e-6),\n",
    "              metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def build_model_with_activation_layers(main_activation_layer, main_activation_name, main_initializer,\n",
    "                                       use_conv_block3=False):\n",
    "    model = Sequential(name=\"cnn_model\")\n",
    "    # Convolution Block 0\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", input_shape=INPUT_SHAPE,\n",
    "              kernel_initializer= main_initializer, name=\"conv_block_0_conv_layer_0_input\"))\n",
    "    model.add(main_activation_layer(name=\"conv_block_0_{}_0\".format(main_activation_name)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\",\n",
    "              kernel_initializer= main_initializer, name=\"conv_block_0_conv_layer_1\"))\n",
    "    model.add(main_activation_layer(name=\"conv_block_0_{}_1\".format(main_activation_name)))\n",
    "    model.add(BatchNormalization(name=\"conv_block_0_batchnorm\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\", name=\"conv_block_0_maxpool\"))\n",
    "    model.add(Dropout(0.25, name=\"conv_block_0_dropout\"))\n",
    "\n",
    "    # Convolution Block 1\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", kernel_regularizer=l2(0.01),\n",
    "              kernel_initializer= main_initializer, name=\"conv_block_1_conv_layer_0\"))\n",
    "    model.add(main_activation_layer(name=\"conv_block_1_{}_0\".format(main_activation_name)))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", kernel_regularizer=l2(0.01),\n",
    "              kernel_initializer= main_initializer, name=\"conv_block_1_conv_layer_1\"))\n",
    "    model.add(main_activation_layer(name=\"conv_block_1_{}_1\".format(main_activation_name)))\n",
    "    model.add(BatchNormalization(name=\"conv_block_1_batchnorm\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"valid\", name=\"conv_block_1_maxpool\"))\n",
    "    model.add(Dropout(0.25, name=\"conv_block_1_dropout\"))\n",
    "        \n",
    "    # Convolution Block 2\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", kernel_regularizer=l2(0.01),\n",
    "              kernel_initializer= main_initializer, name=\"conv_block_2_conv_layer_0\"))\n",
    "    model.add(main_activation_layer(name=\"conv_block_2_{}_0\".format(main_activation_name)))\n",
    "    model.add(Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\", kernel_regularizer=l2(0.01), \n",
    "              kernel_initializer= main_initializer, name=\"conv_block_2_conv_layer_1\"))\n",
    "    model.add(main_activation_layer(name=\"conv_block_2_{}_1\".format(main_activation_name)))\n",
    "    model.add(BatchNormalization(name=\"conv_block_2_batchnorm\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"valid\", name=\"conv_block_2_maxpool\"))\n",
    "    model.add(Dropout(0.25, name=\"conv_block_2_dropout\"))\n",
    "    \n",
    "    # Convolution Block 3\n",
    "    if use_conv_block3:\n",
    "        model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", kernel_regularizer=l2(0.01),\n",
    "                  kernel_initializer= main_initializer, name=\"conv_block_3_conv_layer_0\"))\n",
    "        model.add(main_activation_layer(name=\"conv_block_3_{}_0\".format(main_activation_name)))\n",
    "        model.add(Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\", kernel_regularizer=l2(0.01), \n",
    "                  kernel_initializer= main_initializer, name=\"conv_block_3_conv_layer_1\"))\n",
    "        model.add(main_activation_layer(name=\"conv_block_3_{}_1\".format(main_activation_name)))\n",
    "        model.add(BatchNormalization(name=\"conv_block_3_batchnorm\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"valid\", name=\"conv_block_3_maxpool\"))\n",
    "        model.add(Dropout(0.25, name=\"conv_block_3_dropout\"))\n",
    "\n",
    "    # Classification Block\n",
    "    model.add(Flatten(name=\"class_block_flatten\"))\n",
    "    model.add(Dense(2048, kernel_initializer= main_initializer, name=\"class_block_flatten_dense_0\"))\n",
    "    model.add(main_activation_layer(name=\"class_block_{}_0\".format(main_activation_name)))\n",
    "    model.add(BatchNormalization(name=\"class_block_batchnorm\"))\n",
    "    model.add(Dropout(0.5, name=\"class_block_dropout\"))\n",
    "    model.add(Dense(7, activation=\"softmax\", name=\"class_block_dense_output\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.0001, decay=1e-6),\n",
    "              metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kn0Z_MmHR0yt",
   "metadata": {
    "id": "kn0Z_MmHR0yt"
   },
   "source": [
    "### Early stopping callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p6bwkyo5R0yu",
   "metadata": {
    "id": "p6bwkyo5R0yu"
   },
   "outputs": [],
   "source": [
    "early_stopping_cb = EarlyStopping(min_delta=0.00005, patience=11, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tBLRTBV_R0yu",
   "metadata": {
    "id": "tBLRTBV_R0yu"
   },
   "source": [
    "### Reduce learning rate on plateau callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JHdcC0DaR0yv",
   "metadata": {
    "id": "JHdcC0DaR0yv"
   },
   "outputs": [],
   "source": [
    "reduce_lr_cb = ReduceLROnPlateau(factor=0.5, patience=7, min_l=1e-7, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QC6W089cR0yv",
   "metadata": {
    "id": "QC6W089cR0yv"
   },
   "source": [
    "### Grid Search Hyperparameters for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4wdiDF4qR0yv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wdiDF4qR0yv",
    "outputId": "bb0e630d-0a3c-41c8-85c4-c91cec76560b"
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\"main_activation\": [\"relu\", \"elu\"], \"main_initializer\":[\"he_normal\"], \"use_conv_block3\": [True, False]},\n",
    "    {\"main_activation\": [\"selu\"], \"main_initializer\":[\"lecun_normal\"], \"use_conv_block3\": [True, False]},\n",
    "    {\"main_activation_layer\": [LeakyReLU], \"main_activation_name\": [\"leaky_relu\"],\n",
    "     \"main_initializer\":[\"he_normal\"], \"use_conv_block3\": [True, False]}\n",
    "]\n",
    "\n",
    "best_model = None\n",
    "best_model_accuracy = None\n",
    "best_model_history = None\n",
    "best_model_name = \"\"\n",
    "convolution_blocks = [3, 4]\n",
    "scores = {}\n",
    "\n",
    "for params in list(ParameterGrid(param_grid)):\n",
    "    cur_name = \"\"\n",
    "    cur_model = None\n",
    "    \n",
    "    # Build model from paramters\n",
    "    if \"main_activation\" in params:\n",
    "        cur_name = \"{}+{}+{}-convolution-blocks\".format(params[\"main_activation\"], params[\"main_initializer\"],\n",
    "                                     convolution_blocks[params[\"use_conv_block3\"]])\n",
    "        cur_model = build_model(**params)\n",
    "    else:\n",
    "        cur_name = \"{}+{}+{}-convolution-blocks\".format(params[\"main_activation_name\"], params[\"main_initializer\"],\n",
    "                                     convolution_blocks[params[\"use_conv_block3\"]])\n",
    "        cur_model = build_model_with_activation_layers(**params)\n",
    "    print(cur_name)\n",
    "    if cur_model is None:\n",
    "        continue\n",
    "        \n",
    "    # Save model architecture as JSON\n",
    "    model_json = cur_model.to_json()\n",
    "    with open(cur_name + \".json\", \"w\") as f:\n",
    "        f.write(model_json)\n",
    "        \n",
    "    # Train model\n",
    "    csv_cb = CSVLogger(cur_name + \"-training.csv\")\n",
    "    cur_weights = cur_name + \"-weights.h5\"\n",
    "    checkpoint_cb = ModelCheckpoint(cur_weights, monitor = 'accuracy', verbose =1, \n",
    "                                    save_best_only = True, save_weights_only = True)\n",
    "    history = cur_model.fit(Xy_train, epochs=80,\n",
    "                            validation_data=(Xy_valid),\n",
    "                            steps_per_epoch=Xy_train.n // BATCH_SIZE,\n",
    "                            validation_steps=Xy_valid.n // BATCH_SIZE,\n",
    "                            callbacks=[early_stopping_cb, reduce_lr_cb, \n",
    "                                       csv_cb, checkpoint_cb])\n",
    "    \n",
    "    # Save statistics and compare accuracies\n",
    "    cur_model.load_weights(cur_weights)\n",
    "    loss, accuracy = cur_model.evaluate(Xy_test)\n",
    "    scores[accuracy] = [cur_name, loss]\n",
    "    if best_model_accuracy is None or accuracy > best_model_accuracy:\n",
    "        best_model_accuracy = accuracy\n",
    "        best_model = cur_model\n",
    "        best_model_history = history\n",
    "        best_model_name = cur_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8dd7b1",
   "metadata": {
    "id": "9b8dd7b1"
   },
   "source": [
    "### Print best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e633fc7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e633fc7d",
    "outputId": "8d3d5132-b094-4f84-8e97-08bc1f0b5f26"
   },
   "outputs": [],
   "source": [
    "print(\"Best Model: {} Accuracy: {}\".format(best_model_name, best_model_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedf0b59",
   "metadata": {
    "id": "dedf0b59"
   },
   "source": [
    "### Print model accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a328c9e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4a328c9e",
    "outputId": "cb824826-c4e2-4aee-da33-cce482fc1b5e"
   },
   "outputs": [],
   "source": [
    "for accuracy in sorted(scores.keys(), reverse=True):\n",
    "    name, loss = scores[accuracy]\n",
    "    print(\"Name: {} Accuracy: {} Loss: {}\".format(name, accuracy, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e551f26c",
   "metadata": {
    "id": "e551f26c"
   },
   "source": [
    "### Convert histories into graph images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f1e0d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "82f1e0d9",
    "outputId": "ca73797d-5b9d-49cb-ebfb-ea8e5ee4d619"
   },
   "outputs": [],
   "source": [
    "for csv_file in glob(\"*-training.csv\"):\n",
    "    name = \".\".join(csv_file.split(\".\")[:-1])\n",
    "    training = pd.read_csv(csv_file, index_col=\"epoch\")\n",
    "    fig, ax1 = plt.subplot(1, 1)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Accuracy\", color=\"b\")\n",
    "    ax2.set_ylabel(\"Loss\", color=\"y\")\n",
    "    ax1.plot(training[\"epoch\"], training[\"accuracy\"], \"b-\", label=\"accuracy\")\n",
    "    ax1.plot(training[\"epoch\"], training[\"val_accuracy\"], \"r-\", label=\"val_accuracy\")\n",
    "    ax1.plot(training[\"epoch\"], training[\"lr\"], \"g-\", label=\"lr\")\n",
    "    ax2.plot(training[\"epoch\"], training[\"loss\"], \"y-\", label=\"loss\")\n",
    "    ax2.plot(training[\"epoch\"], training[\"val_loss\"], \"m-\", label=\"val_loss\")\n",
    "    h1, l1 = ax1.get_legend_handles_labels()\n",
    "    h2, l2 = ax2.get_legend_handles_labels()\n",
    "    plt.legend(h1+h2, l1+l2)\n",
    "    plt.title(name)\n",
    "    plt.savefig(name + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fa1d06",
   "metadata": {
    "id": "42fa1d06"
   },
   "source": [
    "### Copy models to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cEpYWIrVMe3X",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "cEpYWIrVMe3X",
    "outputId": "72976bb4-60cc-49c4-d3d6-44b710283b24"
   },
   "outputs": [],
   "source": [
    "for f in os.listdir(\".\"):\n",
    "    shutil.copy(f, GOOGLE_DRIVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "machine_shape": "hm",
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
