{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Analysis\n",
    "#### By Ronny Toribio, Kadir O. Altunel, Michael Cook-Stahl\n",
    "#### Based on [Hands on Machine Learning 2nd edition](https://github.com/ageron/handson-ml2/), [FER2013 candidate 1](https://www.kaggle.com/code/ritikjain00/model-training-fer-13) and [FER2013 candidate 2](https://www.kaggle.com/code/gauravsharma99/facial-emotion-recognition/notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules and declare constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_ZOOM = 0.3\n",
    "IMAGE_SHAPE = (48, 48)\n",
    "INPUT_SHAPE = (48, 48, 1)\n",
    "TRAIN_DIR = os.path.join(\"fer2013\", \"train\")\n",
    "TEST_DIR = os.path.join(\"fer2013\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Facial Emotion Recognition dataset\n",
    "#### training, validation, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=IMAGE_ZOOM, horizontal_flip=True,\n",
    "                                   validation_split=0.10)\n",
    "Xy_train = train_datagen.flow_from_directory(TRAIN_DIR, batch_size=BATCH_SIZE, \n",
    "                                   target_size=IMAGE_SHAPE, shuffle=True, subset=\"training\",\n",
    "                                   color_mode=\"grayscale\", class_mode=\"categorical\")\n",
    "\n",
    "Xy_valid = train_datagen.flow_from_directory(TRAIN_DIR, batch_size=BATCH_SIZE, \n",
    "                                   target_size=IMAGE_SHAPE, shuffle=True, subset=\"validation\",\n",
    "                                   color_mode=\"grayscale\", class_mode=\"categorical\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "Xy_test = test_datagen.flow_from_directory(TEST_DIR, batch_size=BATCH_SIZE * 1000,\n",
    "                                   target_size=IMAGE_SHAPE, shuffle=True,\n",
    "                                   color_mode=\"grayscale\", class_mode=\"categorical\")\n",
    "\n",
    "y_test = Xy_test[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and compile CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(main_activation, main_initializer, use_conv_block2=False):\n",
    "    model = Sequential(name=\"cnn_model\")\n",
    "    # Convolution Block 0\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "              kernel_initializer= main_initializer, input_shape=INPUT_SHAPE,\n",
    "              name=\"conv_block_0_conv_layer_0_input\"))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "              kernel_initializer= main_initializer, name=\"conv_block_0_conv_layer_1\"))\n",
    "    model.add(BatchNormalization(name=\"conv_block_0_batchnorm\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\", name=\"conv_block_0_maxpool\"))\n",
    "    model.add(Dropout(0.25, name=\"conv_block_0_dropout\"))\n",
    "\n",
    "    # Convolution Block 1\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "              kernel_initializer= main_initializer, kernel_regularizer=l2(0.01), name=\"conv_block_1_conv_layer_0\"))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "              kernel_initializer= main_initializer, kernel_regularizer=l2(0.01), name=\"conv_block_1_conv_layer_1\"))\n",
    "    model.add(BatchNormalization(name=\"conv_block_1_batchnorm\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"valid\", name=\"conv_block_1_maxpool\"))\n",
    "    model.add(Dropout(0.25, name=\"conv_block_1_dropout\"))\n",
    "        \n",
    "    # Convolution Block 2\n",
    "    if use_conv_block2:\n",
    "        model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "                  kernel_initializer= main_initializer, kernel_regularizer=l2(0.01),\n",
    "                  name=\"conv_block_2_conv_layer_0\"))\n",
    "        model.add(Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\", activation=main_activation,\n",
    "                  kernel_initializer= main_initializer, kernel_regularizer=l2(0.01), \n",
    "                  name=\"conv_block_2_conv_layer_1\"))\n",
    "        model.add(BatchNormalization(name=\"conv_block_2_batchnorm\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"valid\", name=\"conv_block_2_maxpool\"))\n",
    "        model.add(Dropout(0.25, name=\"conv_block_2_dropout\"))\n",
    "\n",
    "    # Classification Block\n",
    "    model.add(Flatten(name=\"class_block_flatten\"))\n",
    "    model.add(Dense(1024, activation=main_activation, kernel_initializer=\"he_normal\",\n",
    "              name=\"class_block_flatten_dense_0\"))\n",
    "    model.add(BatchNormalization(name=\"class_block_batchnorm\"))\n",
    "    model.add(Dropout(0.5, name=\"class_block_dropout\"))\n",
    "    model.add(Dense(7, activation=\"softmax\", name=\"class_block_dense_output\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.0001, decay=1e-6),\n",
    "              metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = EarlyStopping(min_delta=0.00005, patience=11, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce learning rate on plateau callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr_cb = ReduceLROnPlateau(factor=0.5, patience=7, min_l=1e-7, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Hyperparameters for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\"main_activation\": [\"relu\", \"elu\"], \"main_initializer\":[\"he_normal\"], \"use_conv_block2\": [True, False]},\n",
    "    {\"main_activation\": [\"selu\"], \"main_initializer\":[\"lecun_normal\"], \"use_conv_block2\": [True, False]}\n",
    "]\n",
    "model_scores = {}\n",
    "best_model = None\n",
    "best_model_score = None\n",
    "best_model_history = None\n",
    "\n",
    "for params in list(ParameterGrid(param_grid)):\n",
    "    cur_name = \"{}+{}+{}\".format(params[\"main_activation\"], params[\"main_initializer\"],\n",
    "                                 params[\"use_conv_block2\"])\n",
    "    cur_model = build_model(**params)\n",
    "    history = cur_model.fit(Xy_train, epochs=60,\n",
    "                            validation_data=(Xy_valid),\n",
    "                            steps_per_epoch=Xy_train.n // BATCH_SIZE,\n",
    "                            validation_steps=Xy_valid.n // BATCH_SIZE,\n",
    "                            callbacks=[early_stopping_cb, reduce_lr_cb])\n",
    "    accuracy = cur_model.evaluate(Xy_test)[1]\n",
    "    model_scores[cur_name] = accuracy\n",
    "    if best_model_score is None or accuracy > best_model_score:\n",
    "        best_model_score = accuracy\n",
    "        best_model = cur_model\n",
    "        best_model_history = history\n",
    "\n",
    "model = best_model\n",
    "history = best_model_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Hyperparameters: {}\".format(model_scores.index(best_model_score))\n",
    "for name, score in model_scores.items():\n",
    "      print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.DataFrame(history.history, history.epoch)\n",
    "training.to_csv(\"cnn_model_training.txt\")\n",
    "ax.grid(True)\n",
    "training.plot()\n",
    "plt.savefig(\"cnn_model_training.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model architecture as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"cnn_model.json\", \"w\") as f:\n",
    "    f.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model weights as HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"cnn_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(y_test)\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_test_pred)\n",
    "plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "plt.legend(loc=\"center right\", fontsize=16) # Not shown in the book\n",
    "plt.xlabel(\"Threshold\", fontsize=16)        # Not shown\n",
    "plt.grid(True)                              # Not shown\n",
    "plt.axis([-50000, 50000, 0, 1])             # Not shown\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
